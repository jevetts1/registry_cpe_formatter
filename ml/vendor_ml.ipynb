{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import words\n",
    "import csv,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jayde\\Desktop\\KAZE work\\registry_cpe_formatter\\ml\\vendor_ml.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jayde/Desktop/KAZE%20work/registry_cpe_formatter/ml/vendor_ml.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jayde/Desktop/KAZE%20work/registry_cpe_formatter/ml/vendor_ml.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     inputs_labels\u001b[39m.\u001b[39mremove(line)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jayde/Desktop/KAZE%20work/registry_cpe_formatter/ml/vendor_ml.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(line[\u001b[39m0\u001b[39;49m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jayde/Desktop/KAZE%20work/registry_cpe_formatter/ml/vendor_ml.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     inputs_labels\u001b[39m.\u001b[39mremove(line)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "#parsing data\n",
    "\n",
    "english_word_list = words.words()\n",
    "random.shuffle(english_word_list)\n",
    "english_word_list = list(map(lambda x:[x,0],english_word_list))\n",
    "\n",
    "company_names = pd.read_csv(\"companies_sorted.csv\",usecols = [\"name\"]).values.tolist()\n",
    "company_names = list(map(lambda x:[x[0],1],company_names))[:250000]\n",
    "\n",
    "company_names.extend(english_word_list)\n",
    "\n",
    "inputs_labels = company_names\n",
    "random.shuffle(inputs_labels)\n",
    "\n",
    "for line in inputs_labels:\n",
    "    try:\n",
    "        line[0].lower()\n",
    "    except:\n",
    "        inputs_labels.remove(line)\n",
    "\n",
    "    if len(line[0]) == 0:\n",
    "        inputs_labels.remove(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(lambda x:x[0].replace(\"\",\" \"),inputs_labels))\n",
    "Y = list(map(lambda x:x[1],inputs_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************TOKENISER*********************\n",
    "\n",
    "tkn = Tokenizer()\n",
    "tkn.fit_on_texts(X)\n",
    "total_chars = len(tkn.word_index) + 1\n",
    "\n",
    "tokenised_list = tkn.texts_to_sequences(X)\n",
    "\n",
    "maxSequenceLen = max([len(x) for x in tokenised_list])\n",
    "inputSequences = np.array(pad_sequences(tokenised_list,maxlen = maxSequenceLen,padding = \"pre\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************MODEL*********************\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Embedding(total_chars,50,input_length = maxSequenceLen))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(256,activation = \"relu\"))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"mse\",optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11513/13648 [========================>.....] - ETA: 14:25 - loss: 0.0897ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x0000019A4E182E20>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5133, in <genexpr>\n",
      "    ta.write(ta_index_to_write, out)  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "13648/13648 [==============================] - 5490s 402ms/step - loss: 0.0861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19a61ec9c10>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "model.fit(inputSequences,np.array(Y)epochs = 2,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 243ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2661753]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised_sequence = tkn.texts_to_sequences([\"Ebay\".replace(\"\",\" \")])\n",
    "\n",
    "test_sequence = np.array(pad_sequences(tokenised_sequence,maxlen = maxSequenceLen,padding = \"pre\"))\n",
    "\n",
    "model.predict(test_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1770a777f8a707a68323ad32b77ca7cbf6452a898f6348625ef54424c6744df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
